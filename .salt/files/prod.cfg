# quick and dirty but production ready plone4/plone3 buildout
# For plone 3:
#   take care to enable
#       - the appropriate parts selection
#       - the appropriate programs for your plone version in supervisor
#       - the zeoserver configuration (verify recipe and zeo-conf-additional
#       - the instance options

[buildout]
extensions= buildout-versions mr.developer
prod-parts=
# plone3
#   ${buildout:plone3-parts} 
    env
    grp
    supervisor
    mkdirs
    backup
    zeoserver
    instance
    instance-plain
    instance-worker
    instance1
    instance2
    instance3
    instance4
    balancer.config
    haproxy-build
    crontab
    logrotate
    supervisor.initd
plone3-parts=
    zope2
    productdistros
find-links +=
    ${buildout:extra-find-links}
extra-find-links=

[versions]
buildout-versions = 1.7
collective.recipe.backup = 1.1
collective.recipe.grp = 1.1.0
collective.recipe.template = 1.11
collective.recipe.supervisor = 0.19
meld3 = 0.6.10
mr.developer = 1.31
plone.recipe.haproxy = 1.1.2
python-openid = 2.2.4
supervisor = 3.1.3
uuid = 1.30
argparse = 1.2.2
zdaemon = 4.0.0
ZConfig = 3.0.4
# Plone 3 specific
# zope.testing=3.8.1
# plone.recipe.zope2instance=2.7
# plone.app.blob=1.5.1
# zope.interface=3.5.3
# zope.app.publisher=3.5.2
# zope.securitypolicy=3.4.1
# zope.container=3.8.2
# plone.recipe.zope2zeoserver=1.4
# zope.lifecycleevent=3.6.0
# plone.z3cform=0.5.10
# plone.recipe.zope2install=2.6
# z3c.form=1.9.0
# plone.app.imaging=1.0.5
# plone.app.z3cform=0.4.9
# zope.schema=3.5.4
# zope.publisher=3.5.6
# Pillow=1.7.8
# five.localsitemanager=1.1
# five.intid=0.3.0
# zc.recipe.egg=1.3.2
# zope.proxy=3.4.2
# zope.site=3.6.1
# zope.component=3.5.1
# zope.location=3.5.4
# zc.buildout=1.7.0
# ZODB3=3.8.4
# zope.app.catalog=3.5.2
# zope.app.zcmlfiles=3.4.3
# zope.sendmail=3.5.1
# zope.i18n=3.7.2
# plone.scale= 1.0a2
# archetypes.schemaextender= 2.0.3
# zope.copy= 3.5.0
# zope.location= 3.4.0
# zdaemon= 3.0.5
# ZConfig = 2.9.3
# python-gettext = 1.1

[zope2]
# For more information on this step and configuration options see:
# http://pypi.python.org/pypi/plone.recipe.zope2install
recipe = plone.recipe.zope2install
fake-zope-eggs = true
skip-fake-eggs =
    ZODB3
additional-fake-eggs =
    ZopeUndo
url = ${versions:zope2-url}

[zeoserver]
order=${zope2:recipe}
# for plone 3 use
# recipe = plone.recipe.zope2zeoserver
# zope2-location = ${buildout:parts-directory}/zope2
recipe = plone.recipe.zeoserver
zeopack-script-name=zeoserver-zeopack
pack-days=${v:zeo-pack-days}
blob-storage = ${locations:blob-storage}
zeo-address=${hosts:zeo}:${ports:zeo}
socket-name= ${buildout:directory}/var/zeo.zdsock
zeo-conf-additional=
    ${zeoserver:plone4-storage}
plone4-storage=
    ${zeoserver:async-storage}
plone3-storage=
    ${zeoserver:async-storage}
    ${zeoserver:session-storage}
async-storage=
    <filestorage 2>
        path ${buildout:directory}/var/filestorage/Async.fs
    </filestorage>
session-storage=
    %import tempstorage
    <temporarystorage temp>
        name temporary storage for sessioning
    </temporarystorage>
eggs= ${zeoserver:plone4-eggs}
plone3-eggs=
    plone.app.blob
    ${instance:eggs}
plone4-eggs=
    ZopeUndo
    ZODB3
    plone.app.blob
    ${instance:eggs}

[instance]
# plone3:
# zope2-location = ${zeoserver:location}
# eggs+= python-gettext
zeo-client-cache-size=80MB
session-timeout-minutes=90
zeo-client= on
zeo-address=${zeoserver:zeo-address}
verbose-security=off
event-log-level=INFO
z2-log-level=INFO
zodb-cache-size = 50000
zeo-client-cache-size = 5MB
environment-vars =
    zope_i18n_compile_mo_files = true
    TMPDIR = ${locations:tmp}
    ZC_ASYNC_UUID ${buildout:directory}/var/instance-uuid.txt
blob-storage=${zeoserver:blob-storage}
shared-blob=on
zope-conf-additional =
    <zodb_db async>
        cache-size ${instance:zodb-cache-size}
        <zeoclient>
            server ${zeoserver:zeo-address}
            storage 2
            name asyncstorage
            blob-dir ${zeoserver:blob-storage}
            shared-blob-dir on
            var ${buildout:parts-directory}/instance/var
            cache-size ${instance:zeo-client-cache-size}
        </zeoclient>
        mount-point /zasync
    </zodb_db>

[instance-worker]
<= instance
# uncomment for plone.app.async / zc.async !
#[instance]
#zcml-additional =
#    <include package="plone.app.async" file="multi_db_instance.zcml" />
# plone.app.async instance if any
#[instance-worker]
#webdav-address =
#http-address = ${hosts:instance-worker}:${ports:instance-worker}
#zcml-additional =
#    <include package="plone.app.async" file="multi_db_worker.zcml"/>
#environment-vars =
#    zope_i18n_compile_mo_files = true
#    ZC_ASYNC_UUID ${buildout:directory}/var/worker-uuid.txt
#zope-conf-additional =
#    <zodb_db async>
#        cache-size ${instance-worker:zodb-cache-size}
#        <zeoclient>
#            server ${zeoserver:zeo-address}
#            storage 2
#            name asyncstorage
#            blob-dir ${zeoserver:blob-storage}
#            shared-blob-dir on
#            var ${buildout:parts-directory}/worker/var
#            cache-size ${instance-worker:zeo-client-cache-size}
#        </zeoclient>
#        mount-point /zasync
#    </zodb_db>
#    <product-config zc.z3monitor>
#        port ${ports:workermonitor}
#    </product-config>
#zserver-threads = 2
#zeo-address = ${zeoserver:zeo-address}
#blob-storage = ${zeoserver:blob-storage}

[supervisor]
recipe = collective.recipe.supervisor
port = ${hosts:supervisor}:${ports:supervisor}
user = ${v:user}
password = ${v:password}
programs =
    ${supervisor:base-programs}
    ${supervisor:plone-programs}
# plone3
# programs=
#    ${supervisor:base-programs}
#    ${supervisor:plone3-programs}
base-programs =
    50 balancer ${locations:haproxy-path} [-f ${buildout:directory}/etc/loadbalancing/balancer.conf -db] true ${v:sys-user}
plone-programs=
    10 zeoserver ${buildout:parts-directory}/zeoserver/bin/runzeo ${buildout:parts-directory}/zeoserver true ${v:sys-user}
    21 instance1 (autostart=${v:autostart_instance1}) ${buildout:directory}/bin/instance1 [console] true ${v:sys-user}
    21 instance2 (autostart=${v:autostart_instance2}) ${buildout:directory}/bin/instance2 [console] true ${v:sys-user}
    21 instance3 (autostart=${v:autostart_instance3}) ${buildout:directory}/bin/instance3 [console] true ${v:sys-user}
    21 instance4 (autostart=${v:autostart_instance4}) ${buildout:directory}/bin/instance4 [console] true ${v:sys-user}
    21 instance-worker (autostart=${v:autostart_instanceworker}) ${buildout:directory}/bin/instance-worker [console] true ${v:sys-user}

[instance-plain]
<= instance
zeo-client = off
zeo-address =
temporary-storage =

[instance1]
<=instance
http-address = ${hosts:instance1}:${ports:instance1}

[instance2]
<=instance
http-address = ${hosts:instance2}:${ports:instance2}

[instance3]
<=instance
http-address = ${hosts:instance3}:${ports:instance3}

[instance4]
<=instance
http-address = ${hosts:instance4}:${ports:instance4}

[backup]
recipe= collective.recipe.backup
blobbackuplocation= ${locations:blob-backup}/backups
blobsnapshotlocation= ${locations:blob-backup}/snapshots
keep= ${crons:nb_fullbackups_to_keep}
keep_blob_days= ${crons:nb_backups_to_keep}

[locations]
# absolute paths to avoid buildout auto build of reffered part
zope2= ${buildout:parts-directory}/zope2
tmp= ${buildout:directory}/var/tmp
blob-storage= ${buildout:directory}/var/blobstorage/storage
haproxy-path=${buildout:directory}/bin/haproxy
blob-backup= ${buildout:directory}/var/blobstorage/backup

[crons]
nb_fullbackups_to_keep= 5
nb_backups_to_keep= 35

[hosts]
host=localhost
ip=127.0.0.1
zeo=${hosts:ip}
balancer=${hosts:ip}
supervisor=${hosts:ip}
syslog=${hosts:ip}
instance=${hosts:ip}
instance-worker=${hosts:instance}
instance1=${hosts:instance}
instance2=${hosts:instance}
instance3=${hosts:instance}
instance4=${hosts:instance}

[ports]
supervisor=8085
instance-worker=8087
instance1=8081
instance2=8082
instance3=8083
instance4=8084
balancer=8080
zeo=8086

[v]
sharp=#
projet=ploneprod
user=admin
password=admin
autostart_instance1=true
autostart_instance2=false
autostart_instance3=false
autostart_instance4=false
autostart_instanceworker=false
zeopack=${buildout:directory}/${zeoserver:zeopack-script-name}
cron_minute_00=0
cron_hour_00=0
cron_hour_15=00
cron_minute_15=15
cron_hour_30=00
cron_minute_30=30
cron_hour_45=00
cron_minute_45=45
sys-user = ${env:USER}
sys-group = ${grp:GROUP}
logrotate = 52
zeo-pack-days=31


[balancer.config]
recipe = collective.recipe.template
mode=0644
input =  inline:
    global
      log ${hosts:syslog} local6
      maxconn  1024
      ulimit-n 65536
      nbproc 1
    defaults
      mode http
      option httpclose
      option abortonclose
      retries 3
      option redispatch
      monitor-uri /haproxy-ping
      timeout connect 7s
      timeout queue   15s
      timeout client  7000s
      timeout server  7000s
      stats enable
      stats uri /_plone_balancer_status_
      stats refresh 5s
      stats realm Haproxy\ statistics
      stats auth ${v:user}:${v:password}
    frontend zopecluster
      bind ${hosts:balancer}:${ports:balancer}
      default_backend zope
      capture cookie __ac len 10
      option httplog
    backend zope
      appsession __ac len 32 timeout 1d
      balance roundrobin
      cookie serverid insert indirect
      option httpchk GET /
      server zope0101 ${hosts:instance1}:${ports:instance1} cookie z0101 check maxconn 2 maxqueue 50
      server zope0102 ${hosts:instance2}:${ports:instance2} cookie z0102 check maxconn 2 maxqueue 50
      server zope0103 ${hosts:instance3}:${ports:instance3} cookie z0103 check maxconn 2 maxqueue 50
      server zope0104 ${hosts:instance4}:${ports:instance4} cookie z0104 check maxconn 2 maxqueue 50
output = ${buildout:directory}/etc/loadbalancing/balancer.conf

[crontab]
recipe = collective.recipe.template
input =  inline:
         ${v:cron_minute_00} ${v:cron_hour_00} * * * ${v:sys-user} if [ "x${v:autostart_instance1}" = "xtrue" ];then "${buildout:directory}/bin/supervisorctl" restart balancer;fi
         ${v:cron_minute_00} ${v:cron_hour_00} * * * ${v:sys-user} if [ "x${v:autostart_instance1}" = "xtrue" ];then "${buildout:directory}/bin/supervisorctl" restart instance1;fi
         ${v:cron_minute_00} ${v:cron_hour_00} * * * ${v:sys-user} if [ "x${v:autostart_instance2}" = "xtrue" ];then "${buildout:directory}/bin/supervisorctl" restart instance2;fi
         ${v:cron_minute_00} ${v:cron_hour_00} * * * ${v:sys-user} if [ "x${v:autostart_instance3}" = "xtrue" ];then "${buildout:directory}/bin/supervisorctl" restart instance3;fi
         ${v:cron_minute_00} ${v:cron_hour_00} * * * ${v:sys-user} if [ "x${v:autostart_instance4}" = "xtrue" ];then "${buildout:directory}/bin/supervisorctl" restart instance4;fi
         ${v:cron_minute_00} ${v:cron_hour_00} * * * ${v:sys-user} if [ -e "${v:zeopack}" ];then "${v:zeopack}":fi
         ${v:cron_minute_15} ${v:cron_hour_15} * * * ${v:sys-user} if [ -e "${buildout:directory}/bin/backup" ];then "${buildout:directory}/bin/backup":fi
         ${v:cron_minute_45} ${v:cron_hour_45} * * 6 ${v:sys-user} if [ -e "${buildout:directory}/bin/snapshotbackup" ];then "${buildout:directory}/bin/snapshotbackup":fi
output = ${buildout:directory}/etc/crontab
mode=0644

[supervisor.initd]
recipe = collective.recipe.template
input =  inline:
    ${v:sharp}!/usr/bin/env bash
    ${v:sharp} RedHat startup script for a supervisor instance
    ${v:sharp} chkconfig: - 90 15
    ${v:sharp} description: supervisor init script
    ${v:sharp}${v:sharp}${v:sharp} BEGIN INIT INFO
    ${v:sharp} Provides:          ${v:project}
    ${v:sharp} Required-Start:    $syslog $network $time
    ${v:sharp} Required-Stop:     $syslog $network
    ${v:sharp} Should-Start:
    ${v:sharp} Should-Stop:
    ${v:sharp} Default-Start:     2 3 4 5
    ${v:sharp} Default-Stop:      0 1 6
    ${v:sharp} Short-Description: ${v:project}
    ${v:sharp} Description:       ${v:project}
    ${v:sharp}${v:sharp}${v:sharp} END INIT INFO
    TMPDIR="${locations:tmp}"
    EFFECTIVE_USER="${v:sys-user}"
    INSTANCE_PATH="${buildout:directory}"
    INSTANCE_NAME="$(basename ${buildout:directory})"
    supervisorctl="${buildout:directory}/bin/supervisorctl"
    supervisord="${buildout:directory}/bin/supervisord"
    name="supervisord_${v:project}_$INSTANCE_NAME"
    export TMPDIR
    [ -f $supervisord ] || exit 1
    [ -f $supervisorctl ] || exit 1
    RETVAL=0
    start() {
        echo -n "Starting $name: "
        if [ "x$(whoami)" = x"root" ];then
            su $EFFECTIVE_USER -c "bash -c \"$supervisord\""
        else
          "$supervisord"
        fi
        RETVAL=$?
        echo
        return $RETVAL
    }
    stop() {
        echo -n "Stopping $name: "
        if [ "x$(whoami)" = "xroot" ];then
            su $EFFECTIVE_USER -c "$supervisorctl shutdown"
        else
            $supervisorctl shutdown
        fi
        RETVAL=$?
        echo
        return $RETVAL
    }
    do_start() {
        start
        for i in $(seq 60);do
           if [ "x$RETVAL" != "x0" ];then
               stop
               sleep 2
               start
           else
               break
           fi
        done
    }
    case "$1" in
             start)
                 do_start
                 ;;
             stop)
                 stop
                 ;;
             restart)
                 stop
                 sleep 2
                 do_start
                 ;;
    esac
    exit $REVAL
    ${v:sharp} vim:set ft=sh:
output = ${buildout:directory}/etc/supervisor.initd
mode=0644

[logrotate]
recipe = collective.recipe.template
input =  inline:
    rotate 4
    weekly
    create
    compress
    delaycompress
    ${buildout:directory}/var/log/instance1*.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        sharedscripts
        postrotate
            /bin/kill -USR2 $(cat ${buildout:directory}/var/instance1.pid)
        endscript
    }
    ${buildout:directory}/var/log/instance2*.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        sharedscripts
        postrotate
            /bin/kill -USR2 $(cat ${buildout:directory}/var/instance2.pid)
        endscript
    }
    ${buildout:directory}/var/log/instance3*.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        sharedscripts
        postrotate
            /bin/kill -USR2 $(cat ${buildout:directory}/var/instance3.pid)
        endscript
    }
    ${buildout:directory}/var/log/instance4*.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        sharedscripts
        postrotate
            /bin/kill -USR2 $(cat ${buildout:directory}/var/instance4.pid)
        endscript
    }
    ${buildout:directory}/var/log/zeoserver.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        postrotate
            /bin/kill -USR2 $(cat ${buildout:directory}/var/zeoserver.pid)
        endscript
    }
    ${buildout:directory}/var/log/instance-worker*.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        sharedscripts
        postrotate
            /bin/kill -USR2 $(cat ${buildout:directory}/var/instance-worker.pid)
        endscript
    }
    ${buildout:directory}/var/log/main*.log {
        user root ${v:sys-group}
        compress
        rotate 10
        daily
        notifempty
        size 10M
        sharedscripts
        postrotate
            /bin/kill -USR1 $(cat ${buildout:directory}/var/main.pid)
        endscript
    }
    ${buildout:directory}/var/log/transform*.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        sharedscripts
        postrotate
            /bin/kill -USR1 $(cat ${buildout:directory}/var/transform.pid)
        endscript
    }
    ${buildout:directory}/var/log/supervisor*.log {
        user root ${v:sys-group}
        compress
        rotate ${v:logrotate}
        daily
        notifempty
        size 10M
        sharedscripts
        missingok
        copytruncate
    }
    ${buildout:directory}/var/log/apache/*_log
    ${buildout:directory}/var/log/apache/*.log {
        user root ${v:sys-group}
        compress
        rotate 10
        daily
        notifempty
        size 10M
        sharedscripts
        missingok
        copytruncate
    }
    ${buildout:directory}/var/log/nginx/*.log {
        user root ${v:sys-group}
        compress
        rotate 10
        daily
        notifempty
        size 10M
        sharedscripts
        missingok
        copytruncate
    }
output = ${buildout:directory}/etc/logrotate.conf
mode=0644

[productdistros]
recipe = plone.recipe.distros
urls =
nested-packages =
version-suffix-packages =

[mkdirs]
recipe = plone.recipe.command
update-command = ${mkdirs:command}
command =
    mkdir -pv ${locations:blob-storage};
    mkdir -pv ${locations:blob-backup};
    mkdir -pv ${locations:blob-storage};
    mkdir -pv ${locations:blob-backup};
    mkdir -pv ${locations:tmp};
    mkdir -pv ${buildout:directory}/var/log/apache;
    mkdir -pv ${buildout:directory}/var/log/nginx;
    mkdir -pv ${buildout:directory}/var/backups;\
    mkdir -pv ${buildout:directory}/var/snapshotbackups

[env]
recipe = collective.recipe.environment
PS1 =
TERMCAP =
SSH_CLIENT =
SSH_TTY =
SSH_CONNECTION =
LANG =
SHELL =

[haproxy-build]
recipe = plone.recipe.haproxy
url =  https://github.com/makinacorpus/makina-states/releases/download/attachedfiles/haproxy-1.5.9.tar.gz
target = generic

[grp]
recipe = collective.recipe.grp

